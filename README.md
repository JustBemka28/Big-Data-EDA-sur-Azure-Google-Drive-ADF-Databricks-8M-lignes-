# Traitement de donnÃ©es criminelles avec Azure & Spark (8M lignes)

Ce projet illustre la mise en place dâ€™un mini-pipeline cloud pour lâ€™analyse exploratoire dâ€™un jeu de donnÃ©es de grande taille (8 millions de lignes) en utilisant les services Azure.

## ğŸ“Š Objectif
Explorer et nettoyer un jeu de donnÃ©es criminelles pour en faciliter lâ€™analyse, la comprÃ©hension et la visualisation.

## ğŸ§° Outils utilisÃ©s

- **Azure Data Factory** : pour lâ€™ingestion de donnÃ©es depuis Google Drive
- **Azure Storage Account** : pour le stockage des fichiers bruts
- **Azure Databricks (Spark + Python)** : pour le traitement, lâ€™EDA et la visualisation
- **PySpark** : pour la transformation, le nettoyage, la manipulation
- **Seaborn / Matplotlib** : pour les graphiques

## ğŸ”„ Pipeline

1. ğŸ“¥ **Ingestion** : via un pipeline Azure Data Factory (source HTTP â†’ Azure Blob)
2. ğŸš€ **Traitement Spark** :
   - Chargement du CSV (8M lignes)
   - Renommage des colonnes en franÃ§ais
   - Conversion des dates en format timestamp
   - Suppression des valeurs nulles et doublons
   - Visualisation des types dâ€™infractions, annÃ©es, etc.

## ğŸ“ Structure du projet

- `notebooks/` : Notebook Databricks pour lâ€™analyse
- `pipeline/` : Fichiers liÃ©s Ã  Azure Data Factory
- `Crimes.csv` : Exemple de fichier source (ou lien vers Google Drive)

## ğŸ”— DonnÃ©es

[Lien vers Google Drive pour tÃ©lÃ©charger le fichier]([https://drive.google.com/...](https://drive.google.com/file/d/157qJvi8bd5Gug2mBMyKzKzKZE71Us7_K/view?usp=sharing)
